{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80241b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense ,Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,accuracy_score, mean_squared_error\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2aa237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockyAiTrain:\n",
    "    \n",
    "    def __init__(self,ticker):\n",
    "        self.ticker=ticker\n",
    "        self.Train_data=\"\"\n",
    "        self.today=dt.date.today()\n",
    "        self.T_DF=''\n",
    "        self.Train_data_scaled=\"\"\n",
    "        self.trainY_open=''\n",
    "        self.trainY_high=''\n",
    "        self.trainY_low=''\n",
    "        self.trainY_close=''\n",
    "        self.scaler = StandardScaler()\n",
    "        self.final_df= pd.DataFrame()\n",
    "        self.pre_pro_data()\n",
    "        self.holidays = ['2022-01-26','2022-03-01','2022-03-18','2022-04-14','2022-04-15','2022-05-03','2022-08-09','2022-08-15','2022-08-31','2022-10-05','2022-10-26','2022-11-08']\n",
    "        self.Training()\n",
    "        \n",
    "    def pre_pro_data(self):\n",
    "        ticker_obj = yf.Ticker(self.ticker)\n",
    "        T_DF=ticker_obj.history(period='1y')\n",
    "        T_DF.drop(['Dividends','Stock Splits','Volume'],axis=1,inplace=True)\n",
    "        T_DF=T_DF.reset_index()\n",
    "        T_DF=T_DF[T_DF['Date']>'2000-01-01']\n",
    "        T_dates = T_DF['Date']\n",
    "        Train_data=T_DF.drop('Date',axis=1)\n",
    "        self.T_DF=T_DF\n",
    "        self.scaler = self.scaler.fit(Train_data)\n",
    "        Train_data_scaled = self.scaler.transform(Train_data)\n",
    "        self.Train_data=Train_data\n",
    "        trainX=[]\n",
    "        trainY_open=[]\n",
    "        trainY_high=[]\n",
    "        trainY_low=[]\n",
    "        trainY_close=[]\n",
    "        n_future=1\n",
    "        n_past=14\n",
    "        for i in range(n_past, len(Train_data_scaled) - n_future +1):\n",
    "            trainX.append(Train_data_scaled[i - n_past:i, 0:Train_data.shape[1]])\n",
    "            trainY_open.append(Train_data_scaled[i + n_future - 1:i + n_future, 0])\n",
    "            trainY_high.append(Train_data_scaled[i + n_future - 1:i + n_future, 1])\n",
    "            trainY_low.append(Train_data_scaled[i + n_future - 1:i + n_future, 2])\n",
    "            trainY_close.append(Train_data_scaled[i + n_future - 1:i + n_future, 3])\n",
    "        trainX,trainY_open,trainY_high,trainY_low,trainY_close= np.array(trainX),np.array(trainY_open),np.array(trainY_high),np.array(trainY_low),np.array(trainY_close)\n",
    "        self.trainX=trainX\n",
    "        self.trainY_open=trainY_open\n",
    "        self.trainY_high=trainY_high\n",
    "        self.trainY_low=trainY_low\n",
    "        self.trainY_close=trainY_close\n",
    "        \n",
    "    def Training(self):\n",
    "        #Sequential for Opening\n",
    "        model_open = Sequential()\n",
    "        model_open.add(LSTM(64, activation='relu', input_shape=(self.trainX.shape[1],self.trainX.shape[2]) ,return_sequences=True))\n",
    "        model_open.add(LSTM(32, activation= 'relu', return_sequences= False))\n",
    "        model_open.add(Dropout(0.2))\n",
    "        model_open.add(Dense(self.trainY_open.shape[1]))\n",
    "        model_open.compile(loss='mse',optimizer='adam')\n",
    "\n",
    "        #Sequential for High\n",
    "        model_high = Sequential()\n",
    "        model_high.add(LSTM(64, activation='relu', input_shape=(self.trainX.shape[1],self.trainX.shape[2]) ,return_sequences=True))\n",
    "        model_high.add(LSTM(32, activation= 'relu', return_sequences= False))\n",
    "        model_high.add(Dropout(0.2))\n",
    "        model_high.add(Dense(self.trainY_high.shape[1]))\n",
    "        model_high.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        #Sequential for Low\n",
    "        model_low = Sequential()\n",
    "        model_low.add(LSTM(64, activation='relu', input_shape=(self.trainX.shape[1],self.trainX.shape[2]) ,return_sequences=True))\n",
    "        model_low.add(LSTM(32, activation= 'relu', return_sequences= False))\n",
    "        model_low.add(Dropout(0.2))\n",
    "        model_low.add(Dense(self.trainY_low.shape[1]))\n",
    "        model_low.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        #Sequential for Close\n",
    "        model_close = Sequential()\n",
    "        model_close.add(LSTM(64, activation='relu', input_shape=(self.trainX.shape[1],self.trainX.shape[2]) ,return_sequences=True))\n",
    "        model_close.add(LSTM(32, activation= 'relu', return_sequences= False))\n",
    "        model_close.add(Dropout(0.2))\n",
    "        model_close.add(Dense(self.trainY_close.shape[1]))\n",
    "        model_close.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Model Trainging\n",
    "        tf.config.run_functions_eagerly(True)\n",
    "        print('Opening sctock price training Started....')\n",
    "        history_open = model_open.fit(self.trainX, self.trainY_open, epochs=24, batch_size= 12, validation_split= 0.1, verbose =1 )\n",
    "        print('Opening sctock price training Ended....')\n",
    "        print('High sctock price training Started....')\n",
    "        history_high = model_high.fit(self.trainX, self.trainY_high, epochs=24, batch_size= 12, validation_split= 0.1, verbose =1 )\n",
    "        print('High sctock price training Ended....')\n",
    "        print('Low sctock price training Started....')\n",
    "        history_low = model_low.fit(self.trainX, self.trainY_low, epochs=24, batch_size= 12, validation_split= 0.1, verbose =1 )\n",
    "        print('Low sctock price training Ended....')\n",
    "        print('Closeing sctock price training Started....')\n",
    "        history_close = model_close.fit(self.trainX, self.trainY_close, epochs=24, batch_size= 12, validation_split= 0.1, verbose =1 )\n",
    "        print('Closeing sctock price training Ended....')\n",
    "        \n",
    "        #Exporting PKL\n",
    "        model_open.save('Models/{}_open.h5'.format(self.ticker))\n",
    "        model_high.save('Models/{}_high.h5'.format(self.ticker))\n",
    "        model_low.save('Models/{}_low.h5'.format(self.ticker))\n",
    "        model_close.save('Models/{}_close.h5'.format(self.ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ee9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening sctock price training Started....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praveen\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "18/18 [==============================] - 10s 268ms/step - loss: 0.5714 - val_loss: 0.1018\n",
      "Epoch 2/24\n",
      "18/18 [==============================] - 4s 245ms/step - loss: 0.3342 - val_loss: 0.0787\n",
      "Epoch 3/24\n",
      "18/18 [==============================] - 4s 217ms/step - loss: 0.3010 - val_loss: 0.0758\n",
      "Epoch 4/24\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.2367 - val_loss: 0.0541\n",
      "Epoch 5/24\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.2032 - val_loss: 0.0562\n",
      "Epoch 6/24\n",
      "18/18 [==============================] - 3s 170ms/step - loss: 0.2082 - val_loss: 0.0430\n",
      "Epoch 7/24\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.1663 - val_loss: 0.0382\n",
      "Epoch 8/24\n",
      "18/18 [==============================] - 4s 196ms/step - loss: 0.1517 - val_loss: 0.0307\n",
      "Epoch 9/24\n",
      "18/18 [==============================] - 3s 177ms/step - loss: 0.1322 - val_loss: 0.0276\n",
      "Epoch 10/24\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 0.1288 - val_loss: 0.0293\n",
      "Epoch 11/24\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.1546 - val_loss: 0.0263\n",
      "Epoch 12/24\n",
      "18/18 [==============================] - 4s 202ms/step - loss: 0.1175 - val_loss: 0.0289\n",
      "Epoch 13/24\n",
      "18/18 [==============================] - 3s 176ms/step - loss: 0.1136 - val_loss: 0.0324\n",
      "Epoch 14/24\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.1285 - val_loss: 0.0189\n",
      "Epoch 15/24\n",
      "18/18 [==============================] - 4s 198ms/step - loss: 0.1145 - val_loss: 0.0183\n",
      "Epoch 16/24\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1063 - val_loss: 0.0288\n",
      "Epoch 17/24\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.1297 - val_loss: 0.0175\n",
      "Epoch 18/24\n",
      "18/18 [==============================] - 4s 205ms/step - loss: 0.0963 - val_loss: 0.0147\n",
      "Epoch 19/24\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.0910 - val_loss: 0.0143\n",
      "Epoch 20/24\n",
      "18/18 [==============================] - 3s 192ms/step - loss: 0.0890 - val_loss: 0.0161\n",
      "Epoch 21/24\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0854 - val_loss: 0.0233\n",
      "Epoch 22/24\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.0885 - val_loss: 0.0191\n",
      "Epoch 23/24\n",
      "18/18 [==============================] - 3s 172ms/step - loss: 0.0667 - val_loss: 0.0112\n",
      "Epoch 24/24\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.0799 - val_loss: 0.0311\n",
      "Opening sctock price training Ended....\n",
      "High sctock price training Started....\n",
      "Epoch 1/24\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.6705 - val_loss: 0.0915\n",
      "Epoch 2/24\n",
      "18/18 [==============================] - 3s 191ms/step - loss: 0.3157 - val_loss: 0.1002\n",
      "Epoch 3/24\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.2549 - val_loss: 0.0728\n",
      "Epoch 4/24\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.2225 - val_loss: 0.0670\n",
      "Epoch 5/24\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.1973 - val_loss: 0.0553\n",
      "Epoch 6/24\n",
      "18/18 [==============================] - 3s 172ms/step - loss: 0.1719 - val_loss: 0.0515\n",
      "Epoch 7/24\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1640 - val_loss: 0.0536\n",
      "Epoch 8/24\n",
      "18/18 [==============================] - 4s 202ms/step - loss: 0.1753 - val_loss: 0.0449\n",
      "Epoch 9/24\n",
      "18/18 [==============================] - 4s 219ms/step - loss: 0.1570 - val_loss: 0.0466\n",
      "Epoch 10/24\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.1474 - val_loss: 0.0353\n",
      "Epoch 11/24\n",
      "18/18 [==============================] - 3s 176ms/step - loss: 0.1406 - val_loss: 0.0467\n",
      "Epoch 12/24\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.1421 - val_loss: 0.0345\n",
      "Epoch 13/24\n",
      "18/18 [==============================] - 4s 200ms/step - loss: 0.1281 - val_loss: 0.0341\n",
      "Epoch 14/24\n",
      "18/18 [==============================] - 3s 174ms/step - loss: 0.1210 - val_loss: 0.0293\n",
      "Epoch 15/24\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.1327 - val_loss: 0.0356\n",
      "Epoch 16/24\n",
      "18/18 [==============================] - 3s 174ms/step - loss: 0.1525 - val_loss: 0.0342\n",
      "Epoch 17/24\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1248 - val_loss: 0.0288\n",
      "Epoch 18/24\n",
      "18/18 [==============================] - 3s 172ms/step - loss: 0.1079 - val_loss: 0.0248\n",
      "Epoch 19/24\n",
      "18/18 [==============================] - 3s 176ms/step - loss: 0.1226 - val_loss: 0.0254\n",
      "Epoch 20/24\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1130 - val_loss: 0.0283\n",
      "Epoch 21/24\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1000 - val_loss: 0.0351\n",
      "Epoch 22/24\n",
      "18/18 [==============================] - 3s 179ms/step - loss: 0.1147 - val_loss: 0.0390\n",
      "Epoch 23/24\n",
      "18/18 [==============================] - 3s 185ms/step - loss: 0.0954 - val_loss: 0.0277\n",
      "Epoch 24/24\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.1003 - val_loss: 0.0222\n",
      "High sctock price training Ended....\n",
      "Low sctock price training Started....\n",
      "Epoch 1/24\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.8126 - val_loss: 0.0758\n",
      "Epoch 2/24\n",
      "18/18 [==============================] - 4s 245ms/step - loss: 0.4590 - val_loss: 0.0782\n",
      "Epoch 3/24\n",
      "18/18 [==============================] - 4s 209ms/step - loss: 0.4036 - val_loss: 0.0656\n",
      "Epoch 4/24\n",
      "18/18 [==============================] - 4s 226ms/step - loss: 0.2943 - val_loss: 0.0609\n",
      "Epoch 5/24\n",
      "18/18 [==============================] - 6s 329ms/step - loss: 0.3127 - val_loss: 0.0529\n",
      "Epoch 6/24\n",
      "18/18 [==============================] - 4s 246ms/step - loss: 0.2327 - val_loss: 0.0428\n",
      "Epoch 7/24\n",
      "18/18 [==============================] - 4s 197ms/step - loss: 0.2283 - val_loss: 0.0508\n",
      "Epoch 8/24\n",
      "18/18 [==============================] - 4s 248ms/step - loss: 0.1778 - val_loss: 0.0623\n",
      "Epoch 9/24\n",
      "18/18 [==============================] - 5s 272ms/step - loss: 0.2218 - val_loss: 0.0407\n",
      "Epoch 10/24\n",
      "18/18 [==============================] - 5s 273ms/step - loss: 0.2049 - val_loss: 0.0556\n",
      "Epoch 11/24\n",
      "18/18 [==============================] - 5s 267ms/step - loss: 0.1659 - val_loss: 0.0360\n",
      "Epoch 12/24\n",
      "18/18 [==============================] - 5s 278ms/step - loss: 0.1563 - val_loss: 0.0358\n",
      "Epoch 13/24\n",
      "18/18 [==============================] - 5s 262ms/step - loss: 0.1533 - val_loss: 0.0321\n",
      "Epoch 14/24\n",
      "18/18 [==============================] - 4s 237ms/step - loss: 0.1573 - val_loss: 0.0303\n",
      "Epoch 15/24\n",
      "18/18 [==============================] - 4s 202ms/step - loss: 0.1336 - val_loss: 0.0548\n",
      "Epoch 16/24\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1725 - val_loss: 0.0578\n",
      "Epoch 17/24\n",
      "18/18 [==============================] - 3s 177ms/step - loss: 0.1720 - val_loss: 0.0305\n",
      "Epoch 18/24\n",
      "18/18 [==============================] - 3s 170ms/step - loss: 0.1603 - val_loss: 0.0288\n",
      "Epoch 19/24\n",
      "18/18 [==============================] - 3s 168ms/step - loss: 0.1372 - val_loss: 0.0307\n",
      "Epoch 20/24\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1367 - val_loss: 0.0499\n",
      "Epoch 21/24\n",
      "18/18 [==============================] - 3s 193ms/step - loss: 0.1385 - val_loss: 0.0361\n",
      "Epoch 22/24\n",
      "18/18 [==============================] - 3s 194ms/step - loss: 0.1370 - val_loss: 0.0308\n",
      "Epoch 23/24\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1433 - val_loss: 0.0650\n",
      "Epoch 24/24\n",
      "18/18 [==============================] - 3s 190ms/step - loss: 0.1371 - val_loss: 0.0275\n",
      "Low sctock price training Ended....\n",
      "Closeing sctock price training Started....\n",
      "Epoch 1/24\n",
      "18/18 [==============================] - 3s 173ms/step - loss: 0.7015 - val_loss: 0.1209\n",
      "Epoch 2/24\n",
      "18/18 [==============================] - 3s 183ms/step - loss: 0.3583 - val_loss: 0.0808\n",
      "Epoch 3/24\n",
      "18/18 [==============================] - 4s 213ms/step - loss: 0.3223 - val_loss: 0.0693\n",
      "Epoch 4/24\n",
      "18/18 [==============================] - 3s 167ms/step - loss: 0.2806 - val_loss: 0.0568\n",
      "Epoch 5/24\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.2350 - val_loss: 0.0538\n",
      "Epoch 6/24\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.2396 - val_loss: 0.0616\n",
      "Epoch 7/24\n",
      "18/18 [==============================] - 3s 175ms/step - loss: 0.2256 - val_loss: 0.0533\n",
      "Epoch 8/24\n",
      "18/18 [==============================] - 3s 170ms/step - loss: 0.2370 - val_loss: 0.0472\n",
      "Epoch 9/24\n",
      "18/18 [==============================] - 3s 176ms/step - loss: 0.2164 - val_loss: 0.0531\n",
      "Epoch 10/24\n",
      "18/18 [==============================] - 4s 208ms/step - loss: 0.2247 - val_loss: 0.0418\n",
      "Epoch 11/24\n",
      "18/18 [==============================] - 4s 235ms/step - loss: 0.1759 - val_loss: 0.0422\n",
      "Epoch 12/24\n",
      "18/18 [==============================] - 3s 180ms/step - loss: 0.1824 - val_loss: 0.0433\n",
      "Epoch 13/24\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1828 - val_loss: 0.0428\n",
      "Epoch 14/24\n",
      "18/18 [==============================] - 3s 169ms/step - loss: 0.1884 - val_loss: 0.0610\n",
      "Epoch 15/24\n",
      "18/18 [==============================] - 3s 181ms/step - loss: 0.1754 - val_loss: 0.0491\n",
      "Epoch 16/24\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1559 - val_loss: 0.0425\n",
      "Epoch 17/24\n",
      "18/18 [==============================] - 3s 187ms/step - loss: 0.1633 - val_loss: 0.0348\n",
      "Epoch 18/24\n",
      "18/18 [==============================] - 3s 178ms/step - loss: 0.1808 - val_loss: 0.0378\n",
      "Epoch 19/24\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.1530 - val_loss: 0.0334\n",
      "Epoch 20/24\n",
      "18/18 [==============================] - 3s 182ms/step - loss: 0.1475 - val_loss: 0.0425\n",
      "Epoch 21/24\n",
      "18/18 [==============================] - 3s 184ms/step - loss: 0.1699 - val_loss: 0.0299\n",
      "Epoch 22/24\n",
      "18/18 [==============================] - 4s 210ms/step - loss: 0.1552 - val_loss: 0.0345\n",
      "Epoch 23/24\n",
      "18/18 [==============================] - 4s 205ms/step - loss: 0.1515 - val_loss: 0.0373\n",
      "Epoch 24/24\n",
      "18/18 [==============================] - 3s 189ms/step - loss: 0.1629 - val_loss: 0.0472\n",
      "Closeing sctock price training Ended....\n"
     ]
    }
   ],
   "source": [
    "stocky= StockyAiTrain('TATAMOTORS.NS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6be2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockyAIForcast:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def prediction(self,ticker):\n",
    "        #df_forcast=pd.DataFrame()\n",
    "        ticker_obj = yf.Ticker(ticker)\n",
    "        T_DF=ticker_obj.history(period='90d')\n",
    "        T_DF=T_DF.reset_index()\n",
    "        T_DF.drop(['Date','Volume','Dividends','Stock Splits'], axis=1,inplace=True)\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data=scaler.fit_transform(T_DF)\n",
    "        scaled_data = np.array(scaled_data)\n",
    "        trainX=[]\n",
    "        n_future=1\n",
    "        n_past=14\n",
    "        for i in range(n_past, len(scaled_data) - n_future +1):\n",
    "            trainX.append(scaled_data[i - n_past:i, 0:scaled_data.shape[1]])\n",
    "\n",
    "        trainX = np.array(trainX)\n",
    "        holidays = ['2022-01-26','2022-03-01','2022-03-18','2022-04-14','2022-04-15','2022-05-03','2022-08-09','2022-08-15','2022-08-31','2022-10-05','2022-10-26','2022-11-08']\n",
    "        buz_day=CustomBusinessDay(holidays=holidays)\n",
    "        n_feature = 30\n",
    "        forcast_dates = pd.date_range('2022-11-26', periods= n_feature, freq=buz_day).tolist()\n",
    "        n_days_for_prediction=n_feature\n",
    "\n",
    "        model_open = tf.keras.models.load_model('Models/{}_open.h5'.format(ticker))\n",
    "        model_high = tf.keras.models.load_model('Models/{}_high.h5'.format(ticker))\n",
    "        model_low = tf.keras.models.load_model('Models/{}_low.h5'.format(ticker))\n",
    "        model_close = tf.keras.models.load_model('Models/{}_close.h5'.format(ticker))\n",
    "\n",
    "        prediction_open = model_open.predict(trainX[-n_days_for_prediction:])\n",
    "        prediction_high = model_high.predict(trainX[-n_days_for_prediction:])\n",
    "        prediction_low = model_low.predict(trainX[-n_days_for_prediction:])\n",
    "        prediction_close = model_close.predict(trainX[-n_days_for_prediction:])\n",
    "\n",
    "        prediction_copies_open = np.repeat(prediction_open, T_DF.shape[1], axis=-1)\n",
    "        y_pred_future_open = scaler.inverse_transform(prediction_copies_open)[:,0]\n",
    "        prediction_copies_high = np.repeat(prediction_high, T_DF.shape[1], axis=-1)\n",
    "        y_pred_future_high = scaler.inverse_transform(prediction_copies_high)[:,0]\n",
    "        prediction_copies_low = np.repeat(prediction_low, T_DF.shape[1], axis=-1)\n",
    "        y_pred_future_low = scaler.inverse_transform(prediction_copies_low)[:,0]\n",
    "        prediction_copies_close = np.repeat(prediction_close, T_DF.shape[1], axis=-1)\n",
    "        y_pred_future_close = scaler.inverse_transform(prediction_copies_close)[:,0]\n",
    "\n",
    "        df_forcast = pd.DataFrame({'Date':np.array(forcast_dates),'Open':(y_pred_future_open),'High':(y_pred_future_high),'Low':(y_pred_future_low),'Close':(y_pred_future_close)})\n",
    "        df_forcast['Date']=pd.to_datetime(df_forcast['Date'])\n",
    "        return df_forcast\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27325c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = StockyAIForcast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9194875f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12196/953621046.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TATAMOTORS.NS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predic' is not defined"
     ]
    }
   ],
   "source": [
    "predic.prediction('TATAMOTORS.NS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf75011",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_obj = yf.Ticker(\"TATAMOTORS.NS\")\n",
    "T_DF=ticker_obj.history(period='1y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90d5b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df = pd.read_excel('trained tickers.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2f68080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hgcgh\n"
     ]
    }
   ],
   "source": [
    "tik=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b493dfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tickers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Tickers]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bed5407e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "f() got an unexpected keyword argument 'ignore_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12196/389977521.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mticker_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Tickers'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtik\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: f() got an unexpected keyword argument 'ignore_index'"
     ]
    }
   ],
   "source": [
    "ticker_df.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96245e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df.to_excel('trained tickers.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "992fd737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt.datetime.now().strtime(\"%y-%m-%d\")\n",
    "now=dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "becf26fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-18'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df613cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8743faa4f4858d5a40fd41a5149682422031aff00136a0e91fa686edfda7ddc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
